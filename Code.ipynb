{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Value Labs ML.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "hzSvgIgSVIYB"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IHglKkyVIWw",
        "colab_type": "text"
      },
      "source": [
        "## Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlYx15bqVIWz",
        "colab_type": "code",
        "outputId": "09a766d9-2f39-4020-f734-280cd99f7a48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import word_tokenize \n",
        "import gensim\n",
        "nltk.download('punkt')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qplKAZHVIW5",
        "colab_type": "code",
        "outputId": "68b0c5e6-7458-4c7f-e28c-0197aac54b62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import word_tokenize \n",
        "\n",
        "  \n",
        "stop_words = set(stopwords.words('english')) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtbedHpBVIW9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lemmatizer = WordNetLemmatizer() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPpLxOyxVIXA",
        "colab_type": "text"
      },
      "source": [
        "## Importing Data Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRXPT0C3VIXB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=pd.read_csv('Train.csv')\n",
        "df1=pd.read_csv('Test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itljcVklVIXE",
        "colab_type": "text"
      },
      "source": [
        "## Tokenize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYrqNuX0VIXF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for x in range(len(df)):\n",
        "    df['answer_text'][x]=nltk.word_tokenize(df['answer_text'][x])\n",
        "for x in range(len(df)):\n",
        "    df['question'][x]=nltk.word_tokenize(df['question'][x])\n",
        "for x in range(len(df1)):\n",
        "    df1['answer_text'][x]=nltk.word_tokenize(df1['answer_text'][x])\n",
        "for x in range(len(df1)):\n",
        "    df1['question'][x]=nltk.word_tokenize(df1['question'][x])\n",
        "for x in range(len(df)):\n",
        "    df['distractor'][x]=nltk.word_tokenize(df['distractor'][x])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boKOTQprVIXH",
        "colab_type": "text"
      },
      "source": [
        "## Removing Special Characters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azMPkhE_VIXI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for y in range(len(df)):\n",
        "    for k in range(len(df['question'][y])):\n",
        "          df['question'][y][k]= re.sub('\\W',\"\",df['question'][y][k])\n",
        "for y in range(len(df)):\n",
        "    for k in range(len(df['answer_text'][y])):\n",
        "          df['answer_text'][y][k]= re.sub('\\W',\"\",df['answer_text'][y][k])\n",
        "for y in range(len(df1)):\n",
        "    for k in range(len(df1['question'][y])):\n",
        "          df1['question'][y][k]= re.sub('\\W',\"\",df1['question'][y][k])\n",
        "for y in range(len(df1)):\n",
        "    for k in range(len(df1['answer_text'][y])):\n",
        "          df1['answer_text'][y][k]= re.sub('\\W',\"\",df1['answer_text'][y][k])\n",
        "for x in range(len(df)):\n",
        "    for y in range(len(df['distractor'][x])):\n",
        "        df['distractor'][x][y]=re.sub('\\W',\"\",df['distractor'][x][y])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPaocLhXVIXM",
        "colab_type": "text"
      },
      "source": [
        "## Removing Stop Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KnltDgZVIXM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for z in range(len(df)):\n",
        "    df['question'][z]=[w for w in df['question'][z] if not w in stop_words] \n",
        "for z in range(len(df)):\n",
        "    df['answer_text'][z]=[w for w in df['answer_text'][z] if not w in stop_words] \n",
        "for z in range(len(df1)):\n",
        "    df1['question'][z]=[w for w in df1['question'][z] if not w in stop_words] \n",
        "for z in range(len(df1)):\n",
        "    df1['answer_text'][z]=[w for w in df1['answer_text'][z] if not w in stop_words] \n",
        "for z in range(len(df)):\n",
        "    df['distractor'][z]=[w for w in df['distractor'][z] if not w in stop_words] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HefwaFnhVIXP",
        "colab_type": "text"
      },
      "source": [
        "## Converting to Lower Case"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syhfh35iVIXQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for y in range(len(df)):\n",
        "    for k in range(len(df['question'][y])):\n",
        "          df['question'][y][k]= df['question'][y][k].lower()\n",
        "for y in range(len(df)):\n",
        "    for k in range(len(df['answer_text'][y])):\n",
        "          df['answer_text'][y][k]= df['answer_text'][y][k].lower()\n",
        "for y in range(len(df1)):\n",
        "    for k in range(len(df1['question'][y])):\n",
        "          df1['question'][y][k]= df1['question'][y][k].lower()\n",
        "for y in range(len(df1)):\n",
        "    for k in range(len(df1['answer_text'][y])):\n",
        "          df1['answer_text'][y][k]= df1['answer_text'][y][k].lower()\n",
        "for x in range(len(df)):\n",
        "    for y in range(len(df['distractor'][x])):\n",
        "        df['distractor'][x][y]= df['distractor'][x][y].lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMtmUo6mVIXT",
        "colab_type": "text"
      },
      "source": [
        "## Lemonitize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yHuMJkIVIXU",
        "colab_type": "code",
        "outputId": "25c2aed3-cb4e-4eae-8224-dbd4d927f60c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "nltk.download('wordnet')\n",
        "for y in range(len(df)):\n",
        "    for k in range(len(df['question'][y])):\n",
        "          df['question'][y][k]=lemmatizer.lemmatize(df['question'][y][k])\n",
        "for y in range(len(df)):\n",
        "    for k in range(len(df['answer_text'][y])):\n",
        "          df['answer_text'][y][k]=lemmatizer.lemmatize(df['answer_text'][y][k])\n",
        "for y in range(len(df1)):\n",
        "    for k in range(len(df1['question'][y])):\n",
        "          df1['question'][y][k]=lemmatizer.lemmatize(df1['question'][y][k])\n",
        "for y in range(len(df1)):\n",
        "    for k in range(len(df1['answer_text'][y])):\n",
        "          df1['answer_text'][y][k]=lemmatizer.lemmatize(df1['answer_text'][y][k])\n",
        "for x in range(len(df)):\n",
        "    for y in range(len(df['distractor'][x])):\n",
        "        df['distractor'][x][y]=lemmatizer.lemmatize(df['distractor'][x][y])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87Hfu7NNVIXX",
        "colab_type": "text"
      },
      "source": [
        "## Creating Data Set for Word2vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6pcqaEPVIXY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus=[]\n",
        "for y in range(len(df)):\n",
        "    for k in range(len(df['question'][y])):\n",
        "          corpus.append(df['question'][y][k])\n",
        "for y in range(len(df)):\n",
        "    for k in range(len(df['answer_text'][y])):\n",
        "          corpus.append(df['answer_text'][y][k])\n",
        "for y in range(len(df1)):\n",
        "    for k in range(len(df1['question'][y])):\n",
        "          corpus.append(df1['question'][y][k])\n",
        "for y in range(len(df1)):\n",
        "    for k in range(len(df1['answer_text'][y])):\n",
        "          corpus.append(df1['answer_text'][y][k])\n",
        "for y in range(len(df)):\n",
        "    for k in range(len(df['distractor'][y])):\n",
        "          corpus.append(df['distractor'][y][k])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wx5cSJ9SVIXb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = ' '.join(corpus).split()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aplnEhsVIXg",
        "colab_type": "text"
      },
      "source": [
        "## Training Word2vec Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaajV9ILVIXh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import FastText\n",
        "model_2vec = FastText(size=4, window=5, min_count=0)  # instantiate\n",
        "model_2vec.build_vocab(sentences=[corpus])\n",
        "model_2vec.train(sentences=[corpus], total_examples=len(corpus), epochs=10) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-efiyD-VIXk",
        "colab_type": "text"
      },
      "source": [
        "## Creating Dataset for LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_NcMbPvVIXl",
        "colab_type": "code",
        "outputId": "0df26d29-f7ba-4e7f-87b8-d8ef6a8d4b65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "sequences = list()\n",
        "for i in range(1, len(corpus)):\n",
        "    sequence = corpus[i-1:i+1]\n",
        "    sequences.append(sequence)\n",
        "print('Total Sequences: %d' % len(sequences))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Sequences: 693490\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Z7Cq1G43pEu",
        "colab_type": "code",
        "outputId": "fa0c443c-e90d-4d39-f97c-3330ca5d5378",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "vocab_size,emdedding_size,pretrained_weights"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(23332, 4, array([[ 1.32918999e-01,  5.52230453e+00, -1.48271906e+00,\n",
              "          1.06929531e+01],\n",
              "        [ 8.64617750e-02,  1.54479122e+00, -3.64845097e-01,\n",
              "          3.02797961e+00],\n",
              "        [ 3.47182550e-03,  5.06493616e+00, -1.30594122e+00,\n",
              "          9.52754402e+00],\n",
              "        ...,\n",
              "        [ 3.87315415e-02,  1.49336290e+00, -3.89403701e-01,\n",
              "          2.81045341e+00],\n",
              "        [ 6.24258481e-02, -4.73016053e-02,  2.30362099e-02,\n",
              "         -3.11755594e-02],\n",
              "        [ 2.58462299e-02,  4.98061150e-01, -1.22330606e-01,\n",
              "          9.46779072e-01]], dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wR9vGAyRVIXo",
        "colab_type": "code",
        "outputId": "49758da3-04fc-4b2d-a7bb-05ba729ecf69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "max_sentence_len = 10\n",
        "pretrained_weights = model_2vec.wv.syn0\n",
        "vocab_size, emdedding_size = pretrained_weights.shape\n",
        "def idx2word(idx):\n",
        "    return model_2vec.wv.index2word[idx]\n",
        "\n",
        "def word2idx(word):\n",
        "    return model_2vec.wv.vocab[word].index"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTRtiEd2VIXq",
        "colab_type": "code",
        "outputId": "0b3cd376-d8f0-4240-f003-fde14241fa2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\n",
        "print('\\nPreparing the data for LSTM...')\n",
        "train_x = np.zeros([len(sequences), 23440], dtype=np.int32)\n",
        "train_y = np.zeros([len(sequences), 23440], dtype=np.int32)\n",
        "for i in range(len(sequences)):\n",
        "    train_x[i] = word2idx(sequences[i][0])\n",
        "    train_y[i] = word2idx(sequences[i][1])\n",
        "print('train_x shape:', train_x.shape)\n",
        "print('train_y shape:', train_y.shape)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Preparing the data for LSTM...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgN5RP6dlfZh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x=train_x/23332\n",
        "train_y=train_y/23332"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5_bTtI4VIXt",
        "colab_type": "text"
      },
      "source": [
        "## Training LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pt6G-S5VIXu",
        "colab_type": "code",
        "outputId": "448b3df8-eb9e-4426-b05a-6404bc2377ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.callbacks import LambdaCallback\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers import Dense, Activation,Dropout\n",
        "from keras.models import Sequential"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uI_ZNDWhARGr",
        "colab_type": "code",
        "outputId": "d4e2d0b4-93e3-4d19-f00f-2dc3de880cf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "model_2vec.wv.syn0.shape[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ki74UXyOaeFr",
        "colab_type": "code",
        "outputId": "784cc317-6a6c-4669-ff49-9e1e3c040c87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "print('Defining a Simple Keras Model...')\n",
        "model=Sequential()  \n",
        "model.add(Embedding(input_dim=model_2vec.wv.syn0.shape[0],output_dim=model_2vec.wv.syn0.shape[1],weights=[model_2vec.wv.syn0])) \n",
        "model.add(LSTM(units=500))\n",
        "\n",
        "model.add(Dense(23440, activation='softmax'))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Defining a Simple Keras Model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGGZV0eSVIX6",
        "colab_type": "code",
        "outputId": "00d3d4a3-bc3c-46b2-cb86-fe2ea1cb26ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, None, 4)           93328     \n",
            "_________________________________________________________________\n",
            "lstm_10 (LSTM)               (None, 500)               1010000   \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 23440)             11743440  \n",
            "=================================================================\n",
            "Total params: 12,846,768\n",
            "Trainable params: 12,846,768\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhGmnBSyVIX8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.objectives import cosine_proximity\n",
        "model.compile(optimizer='adam', loss='cosine_proximity',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBdzfBGGKQLI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(train_x ,train_y,epochs=1,batch_size=128)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzSvgIgSVIYB",
        "colab_type": "text"
      },
      "source": [
        "## Making Training DataSet For LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9IOE9-VVIYC",
        "colab_type": "text"
      },
      "source": [
        "## Fitting LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HJG79AhVIYD",
        "colab_type": "code",
        "outputId": "1c0b6edd-9196-4281-df48-45f4b216f124",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    if temperature <= 0:\n",
        "        return np.argmax(preds)\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "def generate_next(text):\n",
        "    \n",
        "    word_idxs = [word2idx(word) for word in text.lower().split()]\n",
        "    \n",
        "    for i in range(10):\n",
        "        prediction = model.predict(x=np.array(word_idxs))\n",
        "        \n",
        "        idx = sample(prediction[-1], temperature=0.6)\n",
        "        \n",
        "        word_idxs.append(idx)\n",
        "        l.append(' '.join(idx2word(idx) for idx in word_idxs))\n",
        "        print(l)\n",
        "    \n",
        "# def ans(x):    \n",
        "#     for text in [str_list[x]]:\n",
        "#         sample = generate_next(text)\n",
        "        \n",
        "#         distractor.append(l[-1])\n",
        "\n",
        "\n",
        "# for x in range(13436):\n",
        "#     ans(x)\n",
        "l=[]\n",
        "sample = generate_next('stream')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['stream passage']\n",
            "['stream passage', 'stream passage passage']\n",
            "['stream passage', 'stream passage passage', 'stream passage passage passage']\n",
            "['stream passage', 'stream passage passage', 'stream passage passage passage', 'stream passage passage passage passage']\n",
            "['stream passage', 'stream passage passage', 'stream passage passage passage', 'stream passage passage passage passage', 'stream passage passage passage passage passage']\n",
            "['stream passage', 'stream passage passage', 'stream passage passage passage', 'stream passage passage passage passage', 'stream passage passage passage passage passage', 'stream passage passage passage passage passage passage']\n",
            "['stream passage', 'stream passage passage', 'stream passage passage passage', 'stream passage passage passage passage', 'stream passage passage passage passage passage', 'stream passage passage passage passage passage passage', 'stream passage passage passage passage passage passage passage']\n",
            "['stream passage', 'stream passage passage', 'stream passage passage passage', 'stream passage passage passage passage', 'stream passage passage passage passage passage', 'stream passage passage passage passage passage passage', 'stream passage passage passage passage passage passage passage', 'stream passage passage passage passage passage passage passage passage']\n",
            "['stream passage', 'stream passage passage', 'stream passage passage passage', 'stream passage passage passage passage', 'stream passage passage passage passage passage', 'stream passage passage passage passage passage passage', 'stream passage passage passage passage passage passage passage', 'stream passage passage passage passage passage passage passage passage', 'stream passage passage passage passage passage passage passage passage passage']\n",
            "['stream passage', 'stream passage passage', 'stream passage passage passage', 'stream passage passage passage passage', 'stream passage passage passage passage passage', 'stream passage passage passage passage passage passage', 'stream passage passage passage passage passage passage passage', 'stream passage passage passage passage passage passage passage passage', 'stream passage passage passage passage passage passage passage passage passage', 'stream passage passage passage passage passage passage passage passage passage passage']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}